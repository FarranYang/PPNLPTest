#!/usr/bin/env python
# coding: utf-8

# # ä½œä¸š
# 
# æ›´æ¢TokenEmbeddingé¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨VisualDLæŸ¥çœ‹ç›¸åº”çš„TokenEmbeddingå¯è§†åŒ–æ•ˆæœï¼Œå¹¶å°è¯•æ›´æ¢åçš„TokenEmbeddingè®¡ç®—å¥å¯¹è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚
# æœ¬ä½œä¸šè¯¦ç»†æ­¥éª¤ï¼Œå¯å‚è€ƒ[Day01ä½œä¸šæ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/education/day01.md)ï¼Œè®°å¾—star PaddleNLPï¼Œæ”¶è—èµ·æ¥ï¼Œéšæ—¶è·Ÿè¿›æœ€æ–°åŠŸèƒ½å™¢ã€‚
# 
# **ä½œä¸šç»“æœæäº¤**ï¼š
# 1. æˆªå›¾æäº¤å¯è§†åŒ–ç»“æœï¼ˆå›¾ç‰‡æ³¨æ˜ä½œä¸šå¯è§†åŒ–ç»“æœï¼‰ã€‚
# 2. é€šç¯‡æ‰§è¡Œæ¯æ®µä»£ç ï¼Œå¹¶ä¿ç•™æ‰§è¡Œç»“æœã€‚

# # PaddleNLPè¯å‘é‡åº”ç”¨å±•ç¤º
# 
# 6.7æ—¥NLPç›´æ’­æ‰“å¡è¯¾å¼€å§‹å•¦
# 
# **[ç›´æ’­é“¾æ¥è¯·æˆ³è¿™é‡Œï¼Œæ¯æ™š20:00-21:30ğŸ‘ˆ](http://live.bilibili.com/21689802)**
# 
# **[è¯¾ç¨‹åœ°å€è¯·æˆ³è¿™é‡ŒğŸ‘ˆ](https://aistudio.baidu.com/aistudio/course/introduce/24177)**
# 
# æ¬¢è¿æ¥è¯¾ç¨‹**QQç¾¤**ï¼ˆç¾¤å·:618354318ï¼‰äº¤æµå§~~
# 
# 
# è¯å‘é‡ï¼ˆWord embeddingï¼‰ï¼Œå³æŠŠè¯è¯­è¡¨ç¤ºæˆå®æ•°å‘é‡ã€‚â€œå¥½â€çš„è¯å‘é‡èƒ½ä½“ç°è¯è¯­ç›´æ¥çš„ç›¸è¿‘å…³ç³»ã€‚è¯å‘é‡å·²ç»è¢«è¯æ˜å¯ä»¥æé«˜NLPä»»åŠ¡çš„æ€§èƒ½ï¼Œä¾‹å¦‚è¯­æ³•åˆ†æå’Œæƒ…æ„Ÿåˆ†æã€‚
# 
# <p align="center">
# <img src="https://ai-studio-static-online.cdn.bcebos.com/54878855b1df42f9ab50b280d76906b1e0175f280b0f4a2193a542c72634a9bf" width="60%" height="50%"> <br />
# </p>
# <br><center>å›¾1ï¼šè¯å‘é‡ç¤ºæ„å›¾</center></br>
# 
# PaddleNLPå·²é¢„ç½®å¤šä¸ªå…¬å¼€çš„é¢„è®­ç»ƒEmbeddingï¼Œæ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨`paddlenlp.embeddings.TokenEmbedding`æ¥å£åŠ è½½é¢„è®­ç»ƒEmbeddingï¼Œä»è€Œæå‡è®­ç»ƒæ•ˆæœã€‚æœ¬ç¯‡æ•™ç¨‹å°†ä¾æ¬¡ä»‹ç»`paddlenlp.embeddings.TokenEmbedding`çš„åˆå§‹åŒ–å’Œæ–‡æœ¬è¡¨ç¤ºæ•ˆæœï¼Œå¹¶é€šè¿‡æ–‡æœ¬åˆ†ç±»è®­ç»ƒçš„ä¾‹å­å±•ç¤ºå…¶å¯¹è®­ç»ƒæå‡çš„æ•ˆæœã€‚

# In[1]:


get_ipython().system('pip install --upgrade paddlenlp -i https://pypi.org/simple')


# ## åŠ è½½TokenEmbedding
# 
# `TokenEmbedding()`å‚æ•°
# - `embedding_name`
# å°†æ¨¡å‹åç§°ä»¥å‚æ•°å½¢å¼ä¼ å…¥TokenEmbeddingï¼ŒåŠ è½½å¯¹åº”çš„æ¨¡å‹ã€‚é»˜è®¤ä¸º`w2v.baidu_encyclopedia.target.word-word.dim300`çš„è¯å‘é‡ã€‚
# - `unknown_token`
# æœªçŸ¥tokençš„è¡¨ç¤ºï¼Œé»˜è®¤ä¸º[UNK]ã€‚
# - `unknown_token_vector`
# æœªçŸ¥tokençš„å‘é‡è¡¨ç¤ºï¼Œé»˜è®¤ç”Ÿæˆå’Œembeddingç»´æ•°ä¸€è‡´ï¼Œæ•°å€¼å‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒå‘é‡ã€‚
# - `extended_vocab_path`
# æ‰©å±•è¯æ±‡åˆ—è¡¨æ–‡ä»¶è·¯å¾„ï¼Œè¯è¡¨æ ¼å¼ä¸ºä¸€è¡Œä¸€ä¸ªè¯ã€‚å¦‚å¼•å…¥æ‰©å±•è¯æ±‡åˆ—è¡¨ï¼Œtrainable=Trueã€‚
# - `trainable`
# Embeddingå±‚æ˜¯å¦å¯è¢«è®­ç»ƒã€‚Trueè¡¨ç¤ºEmbeddingå¯ä»¥æ›´æ–°å‚æ•°ï¼ŒFalseä¸ºä¸å¯æ›´æ–°ã€‚é»˜è®¤ä¸ºTrueã€‚

# In[3]:


from paddlenlp.embeddings import TokenEmbedding

# åˆå§‹åŒ–TokenEmbeddingï¼Œ é¢„è®­ç»ƒembeddingæœªä¸‹è½½æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½æ•°æ®
# éœ€è¦æ›´æ¢æ‰€é€‰çš„è¯å‘é‡
token_embedding = TokenEmbedding(embedding_name="w2v.baidu_encyclopedia.target.word-word.dim300")

# æŸ¥çœ‹token_embeddingè¯¦æƒ…
print(token_embedding)


# ### è®¤è¯†ä¸€ä¸‹Embedding
# **`TokenEmbedding.search()`**
# è·å¾—æŒ‡å®šè¯æ±‡çš„è¯å‘é‡ã€‚

# In[4]:


test_token_embedding = token_embedding.search("ä¸­å›½")
print(test_token_embedding)


# **`TokenEmbedding.cosine_sim()`**
# è®¡ç®—è¯å‘é‡é—´ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¯­ä¹‰ç›¸è¿‘çš„è¯è¯­ä½™å¼¦ç›¸ä¼¼åº¦æ›´é«˜ï¼Œè¯´æ˜é¢„è®­ç»ƒå¥½çš„è¯å‘é‡ç©ºé—´æœ‰å¾ˆå¥½çš„è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›ã€‚

# In[6]:


score1 = token_embedding.cosine_sim("å¥³å­©", "ç”·å­©")
score2 = token_embedding.cosine_sim("å¥³å­©", "ä¹¦ç±")
print('score1:', score1)
print('score2:', score2)


# ### è¯å‘é‡æ˜ å°„åˆ°ä½ç»´ç©ºé—´
# 
# ä½¿ç”¨æ·±åº¦å­¦ä¹ å¯è§†åŒ–å·¥å…·[VisualDL](https://github.com/PaddlePaddle/VisualDL)çš„[High Dimensional](https://github.com/PaddlePaddle/VisualDL/blob/develop/docs/components/README_CN.md#High-Dimensional--%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E7%BB%84%E4%BB%B6)ç»„ä»¶å¯ä»¥å¯¹embeddingç»“æœè¿›è¡Œå¯è§†åŒ–å±•ç¤ºï¼Œä¾¿äºå¯¹å…¶ç›´è§‚åˆ†æï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š
# 
# 1. å‡çº§ VisualDL æœ€æ–°ç‰ˆæœ¬ã€‚
# 
# `pip install --upgrade visualdl`
# 
# 2. åˆ›å»ºLogWriterå¹¶å°†è®°å½•è¯å‘é‡ã€‚
# 
# 3. ç‚¹å‡»å·¦ä¾§é¢æ¿ä¸­çš„å¯è§†åŒ–tabï¼Œé€‰æ‹©â€˜token_hidiâ€™ä½œä¸ºæ–‡ä»¶å¹¶å¯åŠ¨VisualDLå¯è§†åŒ–

# In[7]:


get_ipython().system('pip install --upgrade visualdl')


# In[8]:


# è·å–è¯è¡¨ä¸­å‰1000ä¸ªå•è¯
labels = token_embedding.vocab.to_tokens(list(range(0, 1000)))
# å–å‡ºè¿™1000ä¸ªå•è¯å¯¹åº”çš„Embedding
test_token_embedding = token_embedding.search(labels)

# å¼•å…¥VisualDLçš„LogWriterè®°å½•æ—¥å¿—
from visualdl import LogWriter

with LogWriter(logdir='./token_hidi') as writer:
    writer.add_embeddings(tag='test', mat=[i for i in test_token_embedding], metadata=labels)


# #### å¯åŠ¨VisualDLæŸ¥çœ‹è¯å‘é‡é™ç»´æ•ˆæœ
# å¯åŠ¨æ­¥éª¤ï¼š
# - 1ã€åˆ‡æ¢åˆ°ã€Œå¯è§†åŒ–ã€æŒ‡å®šå¯è§†åŒ–æ—¥å¿—
# - 2ã€æ—¥å¿—æ–‡ä»¶é€‰æ‹© 'token_hidi'
# - 3ã€ç‚¹å‡»ã€Œå¯åŠ¨VisualDLã€åç‚¹å‡»ã€Œæ‰“å¼€VisualDLã€ï¼Œé€‰æ‹©ã€Œé«˜ç»´æ•°æ®æ˜ å°„ã€ï¼Œå³å¯æŸ¥çœ‹è¯è¡¨ä¸­å‰1000è¯UMAPæ–¹æ³•ä¸‹æ˜ å°„åˆ°ä¸‰ç»´ç©ºé—´çš„å¯è§†åŒ–ç»“æœ:
# 
# ![](https://user-images.githubusercontent.com/48054808/120594172-1fe02b00-c473-11eb-9df1-c0206b07e948.gif)
# 
# å¯ä»¥çœ‹å‡ºï¼Œè¯­ä¹‰ç›¸è¿‘çš„è¯åœ¨è¯å‘é‡ç©ºé—´ä¸­èšé›†(å¦‚æ•°å­—ã€ç« èŠ‚ç­‰)ï¼Œè¯´æ˜é¢„è®­ç»ƒå¥½çš„è¯å‘é‡æœ‰å¾ˆå¥½çš„æ–‡æœ¬è¡¨ç¤ºèƒ½åŠ›ã€‚
# 
# ä½¿ç”¨VisualDLé™¤å¯è§†åŒ–embeddingç»“æœå¤–ï¼Œè¿˜å¯ä»¥å¯¹æ ‡é‡ã€å›¾ç‰‡ã€éŸ³é¢‘ç­‰è¿›è¡Œå¯è§†åŒ–ï¼Œæœ‰æ•ˆæå‡è®­ç»ƒè°ƒå‚æ•ˆç‡ã€‚å…³äºVisualDLæ›´å¤šåŠŸèƒ½å’Œè¯¦ç»†ä»‹ç»ï¼Œå¯å‚è€ƒ[VisualDLä½¿ç”¨æ–‡æ¡£](https://github.com/PaddlePaddle/VisualDL/tree/develop/docs)ã€‚

# ## åŸºäºTokenEmbeddingè¡¡é‡å¥å­è¯­ä¹‰ç›¸ä¼¼åº¦
# 
# åœ¨è®¸å¤šå®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿï¼‰ä¸­ï¼Œ éœ€è¦è¡¡é‡ä¸¤ä¸ªå¥å­çš„è¯­ä¹‰ç›¸ä¼¼ç¨‹åº¦ã€‚æ­¤æ—¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¯è¢‹æ¨¡å‹ï¼ˆBag of Wordsï¼Œç®€ç§°BoWï¼‰è®¡ç®—å¥å­çš„è¯­ä¹‰å‘é‡ã€‚
# 
# **é¦–å…ˆ**ï¼Œå°†ä¸¤ä¸ªå¥å­åˆ†åˆ«è¿›è¡Œåˆ‡è¯ï¼Œå¹¶åœ¨TokenEmbeddingä¸­æŸ¥æ‰¾ç›¸åº”çš„å•è¯è¯å‘é‡ï¼ˆword embddingï¼‰ã€‚
# 
# **ç„¶å**ï¼Œæ ¹æ®è¯è¢‹æ¨¡å‹ï¼Œå°†å¥å­çš„word embeddingå åŠ ä½œä¸ºå¥å­å‘é‡ï¼ˆsentence embeddingï¼‰ã€‚
# 
# **æœ€å**ï¼Œè®¡ç®—ä¸¤ä¸ªå¥å­å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
# 
# ### åŸºäºTokenEmbeddingçš„è¯è¢‹æ¨¡å‹
# 
# 
# ä½¿ç”¨`BoWEncoder`æ­å»ºä¸€ä¸ªBoWæ¨¡å‹ç”¨äºè®¡ç®—å¥å­è¯­ä¹‰ã€‚
# 
# * `paddlenlp.TokenEmbedding`ç»„å»ºword-embeddingå±‚
# * `paddlenlp.seq2vec.BoWEncoder`ç»„å»ºå¥å­å»ºæ¨¡å±‚
# 

# In[9]:


import paddle
import paddle.nn as nn
import paddlenlp


class BoWModel(nn.Layer):
    def __init__(self, embedder):
        super().__init__()
        self.embedder = embedder
        emb_dim = self.embedder.embedding_dim
        self.encoder = paddlenlp.seq2vec.BoWEncoder(emb_dim)
        self.cos_sim_func = nn.CosineSimilarity(axis=-1)

    def get_cos_sim(self, text_a, text_b):
        text_a_embedding = self.forward(text_a)
        text_b_embedding = self.forward(text_b)
        cos_sim = self.cos_sim_func(text_a_embedding, text_b_embedding)
        return cos_sim

    def forward(self, text):
        # Shape: (batch_size, num_tokens, embedding_dim)
        embedded_text = self.embedder(text)

        # Shape: (batch_size, embedding_dim)
        summed = self.encoder(embedded_text)

        return summed

model = BoWModel(embedder=token_embedding)


# ### æ„é€ Tokenizer
# ä½¿ç”¨TokenEmbeddingè¯è¡¨æ„é€ Tokenizerã€‚

# In[10]:


from data import Tokenizer
tokenizer = Tokenizer()
tokenizer.set_vocab(vocab=token_embedding.vocab)


# ### ç›¸ä¼¼å¥å¯¹æ•°æ®è¯»å–
# 
# ä»¥æä¾›çš„æ ·ä¾‹æ•°æ®text_pair.txtä¸ºä¾‹ï¼Œè¯¥æ•°æ®æ–‡ä»¶æ¯è¡ŒåŒ…å«ä¸¤ä¸ªå¥å­ã€‚
# 

# In[11]:


text_pairs = {}
with open("text_pair.txt", "r", encoding="utf8") as f:
    for line in f:
        text_a, text_b = line.strip().split("\t")
        if text_a not in text_pairs:
            text_pairs[text_a] = []
        text_pairs[text_a].append(text_b)


# ### æŸ¥çœ‹ç›¸ä¼¼è¯­å¥ç›¸å…³åº¦

# In[12]:


for text_a, text_b_list in text_pairs.items():
    text_a_ids = paddle.to_tensor([tokenizer.text_to_ids(text_a)])

    for text_b in text_b_list:
        text_b_ids = paddle.to_tensor([tokenizer.text_to_ids(text_b)])
        print("text_a: {}".format(text_a))
        print("text_b: {}".format(text_b))
        print("cosine_sim: {}".format(model.get_cos_sim(text_a_ids, text_b_ids).numpy()[0]))
        print()


# ### ä½¿ç”¨VisualDLæŸ¥çœ‹å¥å­å‘é‡

# In[13]:


# å¼•å…¥VisualDLçš„LogWriterè®°å½•æ—¥å¿—
import numpy as np
from visualdl import LogWriter    
# è·å–å¥å­ä»¥åŠå…¶å¯¹åº”çš„å‘é‡
label_list = []
embedding_list = []

for text_a, text_b_list in text_pairs.items():
    text_a_ids = paddle.to_tensor([tokenizer.text_to_ids(text_a)])
    embedding_list.append(model(text_a_ids).flatten().numpy())
    label_list.append(text_a)

    for text_b in text_b_list:
        text_b_ids = paddle.to_tensor([tokenizer.text_to_ids(text_b)])
        embedding_list.append(model(text_b_ids).flatten().numpy())
        label_list.append(text_b)


with LogWriter(logdir='./sentence_hidi') as writer:
    writer.add_embeddings(tag='test', mat=embedding_list, metadata=label_list)


# ### å¯åŠ¨VisualDLè§‚å¯Ÿå¥å­å‘é‡é™ç»´æ•ˆæœ
# 
# æ­¥éª¤å¦‚ä¸Šè¿°è§‚å¯Ÿè¯å‘é‡é™ç»´æ•ˆæœä¸€æ¨¡ä¸€æ ·ã€‚
# ![](https://ai-studio-static-online.cdn.bcebos.com/0e876f3cf1724e90a317ad3f4be233a9eb0313b0e92f475b95675c2ad52d3eb0)
# 
# 
# å¯ä»¥çœ‹å‡ºï¼Œè¯­ä¹‰ç›¸è¿‘çš„å¥å­åœ¨å¥å­å‘é‡ç©ºé—´ä¸­èšé›†(å¦‚æœ‰å…³è¯¾å ‚çš„å¥å­ã€æœ‰å…³åŒ–å­¦æè¿°å¥å­ç­‰)ã€‚

# # PaddleNLPæ›´å¤šé¢„è®­ç»ƒè¯å‘é‡
# PaddleNLPæä¾›61ç§å¯ç›´æ¥åŠ è½½çš„é¢„è®­ç»ƒè¯å‘é‡ï¼Œè®­ç»ƒè‡ªå¤šé¢†åŸŸä¸­è‹±æ–‡è¯­æ–™ã€å¦‚ç™¾åº¦ç™¾ç§‘ã€æ–°é—»è¯­æ–™ã€å¾®åšç­‰ï¼Œè¦†ç›–å¤šç§ç»å…¸è¯å‘é‡æ¨¡å‹ï¼ˆword2vecã€gloveã€fastTextï¼‰ã€æ¶µç›–ä¸åŒç»´åº¦ã€ä¸åŒè¯­æ–™åº“å¤§å°ï¼Œè¯¦è§[PaddleNLP Embedding API](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/embeddings.md)ã€‚

# # é¢„è®­ç»ƒè¯å‘é‡è¾…åŠ©åˆ†ç±»ä»»åŠ¡
# 
# æƒ³å­¦ä¹ è¯å‘é‡æ›´å¤šåº”ç”¨ï¼Œæ¥è¯•è¯•é¢„è®­ç»ƒè¯å‘é‡å¯¹åˆ†ç±»æ¨¡å‹çš„æ”¹å–„æ•ˆæœå§ï¼Œ[è¿™é‡Œ](https://aistudio.baidu.com/aistudio/projectdetail/1283423) è¯•è¯•æŠŠ`paddle.nn.Embedding`æ¢æˆåˆšåˆšå­¦åˆ°çš„é¢„è®­ç»ƒè¯å‘é‡å§ã€‚

# # åŠ å…¥è¯¾ç¨‹äº¤æµç¾¤ï¼Œä¸€èµ·å­¦ä¹ å§
# 
# ç°åœ¨å°±åŠ å…¥è¯¾ç¨‹ç¾¤ï¼Œä¸€èµ·äº¤æµNLPæŠ€æœ¯å§ï¼
# 
# <img src="https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394" width="200" height="250" >
# 
# 
# 
# **[ç›´æ’­é“¾æ¥è¯·æˆ³è¿™é‡Œï¼Œæ¯æ™š20:00-21:30ğŸ‘ˆ](http://live.bilibili.com/21689802)**
# 
# **[è¿˜æ²¡æœ‰æŠ¥åè¯¾ç¨‹ï¼Ÿèµ¶ç´§æˆ³è¿™é‡Œï¼Œè¯¾ç¨‹ã€ä½œä¸šå®‰æ’ç»Ÿç»Ÿåœ¨è¯¾ç¨‹åŒºå“¦ğŸ‘‰ğŸ»](https://aistudio.baidu.com/aistudio/course/introduce/24177)**
